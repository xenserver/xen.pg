From 65b3f145b0383b55444dc3a95cd4d18ea5655fff Mon Sep 17 00:00:00 2001
From: Sergey Dyasli <sergey.dyasli@citrix.com>
Date: Tue, 26 Mar 2019 09:53:25 +0000
Subject: [PATCH 1/2] x86: add XEN_SYSCTL_spec_ctrl

stop_machine infrastructure is copied from live ucode update.
CPUID level 0x00000007:0.edx is updated on each cpu.
CPUID policies are recalculated if there are any CPUID changes.

Signed-off-by: Sergey Dyasli <sergey.dyasli@citrix.com>
diff --git a/xen/arch/x86/cpuid.c b/xen/arch/x86/cpuid.c
index ea06e70..7ee3556 100644
--- a/xen/arch/x86/cpuid.c
+++ b/xen/arch/x86/cpuid.c
@@ -282,7 +282,7 @@ void cpuid_calculate_raw_policy(void)
     p->x86_vendor = boot_cpu_data.x86_vendor;
 }
 
-static void __init calculate_host_policy(void)
+static void calculate_host_policy(void)
 {
     struct cpuid_policy *p = &host_cpuid_policy;
 
@@ -317,7 +317,7 @@ static void __init calculate_host_policy(void)
     }
 }
 
-static void __init guest_common_feature_adjustments(uint32_t *fs)
+static void guest_common_feature_adjustments(uint32_t *fs)
 {
     /* Unconditionally claim to be able to set the hypervisor bit. */
     __set_bit(X86_FEATURE_HYPERVISOR, fs);
@@ -339,7 +339,7 @@ static void __init guest_common_feature_adjustments(uint32_t *fs)
         __set_bit(X86_FEATURE_IBPB, fs);
 }
 
-static void __init calculate_pv_max_policy(void)
+static void calculate_pv_max_policy(void)
 {
     struct cpuid_policy *p = &pv_max_cpuid_policy;
     uint32_t pv_featureset[FSCAPINTS];
@@ -367,7 +367,7 @@ static void __init calculate_pv_max_policy(void)
     p->extd.raw[0xa] = EMPTY_LEAF; /* No SVM for PV guests. */
 }
 
-static void __init calculate_hvm_max_policy(void)
+static void calculate_hvm_max_policy(void)
 {
     struct cpuid_policy *p = &hvm_max_cpuid_policy;
     uint32_t hvm_featureset[FSCAPINTS];
@@ -428,7 +428,7 @@ static void __init calculate_hvm_max_policy(void)
     recalculate_xstate(p);
 }
 
-void __init init_guest_cpuid(void)
+void init_guest_cpuid(void)
 {
     cpuid_calculate_raw_policy();
     calculate_host_policy();
diff --git a/xen/arch/x86/spec_ctrl.c b/xen/arch/x86/spec_ctrl.c
index 3e579cd..6009ea7 100644
--- a/xen/arch/x86/spec_ctrl.c
+++ b/xen/arch/x86/spec_ctrl.c
@@ -16,11 +16,16 @@
  *
  * Copyright (c) 2017-2018 Citrix Systems Ltd.
  */
+#include <xen/cpu.h>
 #include <xen/errno.h>
 #include <xen/init.h>
 #include <xen/lib.h>
+#include <xen/stop_machine.h>
 #include <xen/warning.h>
 
+#include <public/platform.h>
+
+#include <asm/delay.h>
 #include <asm/microcode.h>
 #include <asm/msr.h>
 #include <asm/processor.h>
@@ -1115,6 +1120,164 @@ void __init init_speculation_mitigations(void)
     }
 }
 
+#define MICROCODE_CALLIN_TIMEOUT_US 30000
+#define MICROCODE_UPDATE_TIMEOUT_US 1000000
+
+static atomic_t cpu_in, cpu_out;
+static atomic_t next_cpu;
+
+static unsigned int common_caps;
+static uint32_t *spec_ctrl_status;
+
+/* Wait for CPUs to rendezvous with a timeout (us) */
+static int wait_for_cpus(atomic_t *cnt, unsigned int expect,
+                         unsigned int timeout)
+{
+    while ( atomic_read(cnt) < expect )
+    {
+        if ( timeout <= 0 )
+        {
+            printk("CPU%d: Timeout when waiting for CPUs calling in\n",
+                   smp_processor_id());
+            return -EBUSY;
+        }
+        udelay(1);
+        timeout--;
+    }
+
+    return 0;
+}
+
+static int update_x86_caps(void)
+{
+    int cpu = smp_processor_id();
+    struct cpuinfo_x86 *c = &cpu_data[cpu];
+    unsigned int edx, tmp;
+
+    if ( c->cpuid_level < 0x00000007 )
+        return -ENOSYS;
+
+    /* Intel-defined CPU features, CPUID level 0x00000007:0.edx, word 9 */
+    cpuid_count(0x00000007, 0, &tmp, &tmp, &tmp, &edx);
+    c->x86_capability[cpufeat_word(X86_FEATURE_AVX512_4VNNIW)] = edx;
+
+    /* Find the new common feature subset */
+    if ( common_caps == 0 )
+        common_caps = edx;
+    else
+        common_caps &= edx;
+
+    return 0;
+}
+
+static int recalc_cpuid_policy(void)
+{
+    unsigned int idx = cpufeat_word(X86_FEATURE_AVX512_4VNNIW);
+
+    if ( boot_cpu_data.x86_capability[idx] == common_caps )
+    {
+        /* No new H/W features have been detected */
+        *spec_ctrl_status = XENPF_spec_ctrl_noop;
+        return 0;
+    }
+
+    /* Update the global common feature set */
+    boot_cpu_data.x86_capability[idx] = common_caps;
+
+    /* Recalculate CPUID policies */
+    init_guest_cpuid();
+
+    *spec_ctrl_status = XENPF_spec_ctrl_success;
+
+    return 0;
+}
+
+static int do_x86_caps_update(void *unused)
+{
+    int cpu = smp_processor_id();
+    unsigned int cpu_nr = num_online_cpus();
+    unsigned int finished;
+    int ret;
+    static bool error;
+
+    atomic_inc(&cpu_in);
+    ret = wait_for_cpus(&cpu_in, cpu_nr, MICROCODE_CALLIN_TIMEOUT_US);
+    if ( ret )
+        return ret;
+
+    while ( cpu != atomic_read(&next_cpu) )
+    {
+        finished = atomic_read(&cpu_out);
+        if ( wait_for_cpus(&next_cpu, cpu, MICROCODE_UPDATE_TIMEOUT_US) )
+        {
+            if ( atomic_read(&cpu_out) > finished )
+                continue;
+            printk("Timeout during do_x86_caps_update (finished %d/%d)",
+                   finished, cpu_nr);
+            return -EBUSY;
+        }
+    }
+
+    update_x86_caps();
+
+    finished = atomic_read(&cpu_out);
+    if ( finished == cpu_nr - 1 )
+    {
+        /* This is the last CPU. Update CPUID policy */
+        recalc_cpuid_policy();
+    }
+
+    atomic_set(&next_cpu, cpumask_next(cpu, &cpu_online_map));
+
+    atomic_inc(&cpu_out);
+    finished = atomic_read(&cpu_out);
+    while ( !error && finished != cpu_nr )
+    {
+        /*
+         * During each timeout interval, at least a CPU is expected to
+         * finish its update. Otherwise, something goes wrong.
+         */
+        if ( wait_for_cpus(&cpu_out, finished + 1,
+                           MICROCODE_UPDATE_TIMEOUT_US) && !error )
+        {
+            error = true;
+            printk("Timeout when finishing do_x86_caps_update (finished %d/%d)",
+                   finished, cpu_nr);
+            return -EBUSY;
+        }
+
+        finished = atomic_read(&cpu_out);
+    }
+
+    return 0;
+}
+
+int spec_ctrl_do_op(uint32_t op, uint32_t *status)
+{
+    int ret = 0;
+
+    if ( op != XENPF_spec_ctrl_update )
+        return -EINVAL;
+
+    if ( !get_cpu_maps() )
+        return -EBUSY;
+
+    *status = XENPF_spec_ctrl_error;
+    spec_ctrl_status = status;
+
+    atomic_set(&cpu_in, 0);
+    atomic_set(&cpu_out, 0);
+    atomic_set(&next_cpu, cpumask_first(&cpu_online_map));
+
+    common_caps = 0;
+
+    ret = stop_machine_run(do_x86_caps_update, NULL, NR_CPUS);
+
+    put_cpu_maps();
+
+    return ret;
+}
+
 static void __init __maybe_unused build_assertions(void)
 {
     /* The optimised assembly relies on this alias. */
diff --git a/xen/arch/x86/sysctl.c b/xen/arch/x86/sysctl.c
index 1916a3d..ce4f14e 100644
--- a/xen/arch/x86/sysctl.c
+++ b/xen/arch/x86/sysctl.c
@@ -32,6 +32,7 @@
 #include <xsm/xsm.h>
 #include <asm/psr.h>
 #include <asm/cpuid.h>
+#include <asm/spec_ctrl.h>
 
 const struct cpu_policy system_policies[] = {
     [ XEN_SYSCTL_cpu_policy_raw ] = {
@@ -386,6 +387,16 @@ long arch_do_sysctl(
         break;
     }
 
+    case XEN_SYSCTL_spec_ctrl:
+    {
+        ret = spec_ctrl_do_op(sysctl->u.spec_ctrl.op,
+                              &sysctl->u.spec_ctrl.status);
+        if ( ret == 0 )
+            ret = __copy_field_to_guest(u_sysctl, sysctl,
+                                        u.spec_ctrl) ? -EFAULT : 0;
+    }
+    break;
+
     default:
         ret = -ENOSYS;
         break;
diff --git a/xen/include/asm-x86/spec_ctrl.h b/xen/include/asm-x86/spec_ctrl.h
index ba03bb4..027dfd9 100644
--- a/xen/include/asm-x86/spec_ctrl.h
+++ b/xen/include/asm-x86/spec_ctrl.h
@@ -134,6 +134,8 @@ static always_inline void spec_ctrl_exit_idle(struct cpu_info *info)
      */
 }
 
+int spec_ctrl_do_op(uint32_t op, uint32_t *status);
+
 #endif /* __ASSEMBLY__ */
 #endif /* !__X86_SPEC_CTRL_H__ */
 
diff --git a/xen/include/public/sysctl.h b/xen/include/public/sysctl.h
index c49b4dc..36abb5e 100644
--- a/xen/include/public/sysctl.h
+++ b/xen/include/public/sysctl.h
@@ -1100,6 +1100,18 @@ typedef struct xen_sysctl_cpu_policy xen_sysctl_cpu_policy_t;
 DEFINE_XEN_GUEST_HANDLE(xen_sysctl_cpu_policy_t);
 #endif
 
+struct xen_sysctl_spec_ctrl {
+#define XENPF_spec_ctrl_update  0 /* Try to use new mitigations */
+    uint32_t op;      /* IN */
+#define XENPF_spec_ctrl_success 0 /* New mitigations have been applied.       */
+                                  /* This is returned in case if some H/W     */
+                                  /* feature-bits have disappered! (Note that */
+                                  /* we don't expect this in practice.        */
+#define XENPF_spec_ctrl_noop    1 /* All mitigations are up to date */
+#define XENPF_spec_ctrl_error   2 /* Some error has occured */
+    uint32_t status;  /* OUT */
+};
+
 struct xen_sysctl {
     uint32_t cmd;
 #define XEN_SYSCTL_readconsole                    1
@@ -1130,6 +1142,7 @@ struct xen_sysctl {
 #define XEN_SYSCTL_livepatch_op                  27
 #define XEN_SYSCTL_set_parameter                 28
 #define XEN_SYSCTL_get_cpu_policy                29
+#define XEN_SYSCTL_spec_ctrl                    188
     uint32_t interface_version; /* XEN_SYSCTL_INTERFACE_VERSION */
     union {
         struct xen_sysctl_readconsole       readconsole;
@@ -1162,6 +1175,7 @@ struct xen_sysctl {
 #if defined(__i386__) || defined(__x86_64__)
         struct xen_sysctl_cpu_policy        cpu_policy;
 #endif
+        struct xen_sysctl_spec_ctrl         spec_ctrl;
         uint8_t                             pad[128];
     } u;
 };
