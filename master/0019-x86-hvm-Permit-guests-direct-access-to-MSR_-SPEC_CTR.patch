From 1a594b1206e7a1b4260e595dd8d9b2509bb8c697 Mon Sep 17 00:00:00 2001
From: Andrew Cooper <andrew.cooper3@citrix.com>
Date: Tue, 14 Nov 2017 19:22:28 +0000
Subject: [PATCH] x86/hvm: Permit guests direct access to
 MSR_{SPEC_CTRL,PRED_CMD}

For performance reasons, HVM guests should have direct access to these MSRs
when possible.

Signed-off-by: Andrew Cooper <andrew.cooper3@citrix.com>
diff --git a/xen/arch/x86/domctl.c b/xen/arch/x86/domctl.c
index 93d0256..49e1ca1 100644
--- a/xen/arch/x86/domctl.c
+++ b/xen/arch/x86/domctl.c
@@ -176,6 +176,13 @@ static void update_domain_cpuid_info(struct domain *d,
             uint32_t edx = ctl->edx &
                 (is_hvm_domain(d) ? hvm_featureset : pv_featureset)[FEATURESET_7d0];
 
+            /*
+             * If the IBSRB/STIBP policy has changed, we need to recalculate the
+             * MSR interception bitmaps and STIBP protection default.
+             */
+            call_policy_changed = ((edx ^ p->feat.raw[0].d) &
+                                   (cpufeat_mask(X86_FEATURE_IBRSB) |
+                                    cpufeat_mask(X86_FEATURE_STIBP)));
             p->feat.raw[0].d = edx;
         }
         break;
@@ -245,6 +252,13 @@ static void update_domain_cpuid_info(struct domain *d,
         uint32_t ebx = ctl->ebx &
             (is_hvm_domain(d) ? hvm_featureset : pv_featureset)[FEATURESET_e8b];
 
+        /*
+         * If the IBRB policy has changed, we need to recalculate the MSR
+         * interception bitmaps.
+         */
+        call_policy_changed = (is_hvm_domain(d) &&
+                               ((ebx ^ p->extd.raw[0 /* 8 */].b) &
+                                (cpufeat_mask(X86_FEATURE_IBPB))));
         p->extd.raw[0 /* 8 */].b = ebx;
     }
     break;
diff --git a/xen/arch/x86/hvm/svm/svm.c b/xen/arch/x86/hvm/svm/svm.c
index ff75625..34e9a17 100644
--- a/xen/arch/x86/hvm/svm/svm.c
+++ b/xen/arch/x86/hvm/svm/svm.c
@@ -614,6 +614,7 @@ static void svm_cpuid_policy_changed(struct vcpu *v)
 {
     struct arch_svm_struct *arch_svm = &v->arch.hvm_svm;
     struct vmcb_struct *vmcb = arch_svm->vmcb;
+    const struct cpuid_policy *cp = v->domain->arch.cpuid;
     u32 bitmap = vmcb_get_exception_intercepts(vmcb);
 
     if ( opt_hvm_fep ||
@@ -623,6 +624,10 @@ static void svm_cpuid_policy_changed(struct vcpu *v)
         bitmap &= ~(1U << TRAP_invalid_op);
 
     vmcb_set_exception_intercepts(vmcb, bitmap);
+
+    /* Give access to MSR_PRED_CMD if the guest has been told about it. */
+    svm_intercept_msr(v, MSR_PRED_CMD,
+                      cp->extd.ibpb ? MSR_INTERCEPT_NONE : MSR_INTERCEPT_RW);
 }
 
 static void svm_sync_vmcb(struct vcpu *v)
diff --git a/xen/arch/x86/hvm/vmx/vmx.c b/xen/arch/x86/hvm/vmx/vmx.c
index 63b3867..92d7a72 100644
--- a/xen/arch/x86/hvm/vmx/vmx.c
+++ b/xen/arch/x86/hvm/vmx/vmx.c
@@ -544,6 +544,8 @@ void vmx_update_exception_bitmap(struct vcpu *v)
 
 static void vmx_cpuid_policy_changed(struct vcpu *v)
 {
+    const struct cpuid_policy *cp = v->domain->arch.cpuid;
+
     if ( opt_hvm_fep ||
          (v->domain->arch.x86_vendor != boot_cpu_data.x86_vendor) )
         v->arch.hvm_vmx.exception_bitmap |= (1U << TRAP_invalid_op);
@@ -553,6 +555,22 @@ static void vmx_cpuid_policy_changed(struct vcpu *v)
     vmx_vmcs_enter(v);
     vmx_update_exception_bitmap(v);
     vmx_vmcs_exit(v);
+
+    /*
+     * We can only pass though MSR_SPEC_CTRL if the guest knows about all bits
+     * in it.  Otherwise, Xen may be fixing up in the background.
+     */
+    v->arch.msr->spec_ctrl.direct_access = cp->feat.ibrsb && cp->feat.stibp;
+    if ( v->arch.msr->spec_ctrl.direct_access )
+        vmx_clear_msr_intercept(v, MSR_SPEC_CTRL, VMX_MSR_RW);
+    else
+        vmx_set_msr_intercept(v, MSR_SPEC_CTRL, VMX_MSR_RW);
+
+    /* MSR_PRED_CMD is safe to pass through if the guest knows about it. */
+    if ( cp->feat.ibrsb || cp->extd.ibpb )
+        vmx_clear_msr_intercept(v, MSR_PRED_CMD,  VMX_MSR_RW);
+    else
+        vmx_set_msr_intercept(v, MSR_PRED_CMD,  VMX_MSR_RW);
 }
 
 static int vmx_guest_x86_mode(struct vcpu *v)
diff --git a/xen/arch/x86/msr.c b/xen/arch/x86/msr.c
index 02a7b49..697cc6e 100644
--- a/xen/arch/x86/msr.c
+++ b/xen/arch/x86/msr.c
@@ -132,7 +132,8 @@ int guest_rdmsr(const struct vcpu *v, uint32_t msr, uint64_t *val)
     case MSR_SPEC_CTRL:
         if ( !cp->feat.ibrsb )
             goto gp_fault;
-        *val = vp->spec_ctrl.guest;
+        *val = (vp->spec_ctrl.direct_access
+                ? vp->spec_ctrl.host : vp->spec_ctrl.guest);
         break;
 
     case MSR_INTEL_PLATFORM_INFO:
diff --git a/xen/include/asm-x86/msr.h b/xen/include/asm-x86/msr.h
index 71f6ee1..06fcb4d 100644
--- a/xen/include/asm-x86/msr.h
+++ b/xen/include/asm-x86/msr.h
@@ -194,10 +194,13 @@ struct msr_vcpu_policy
          * Only the bottom two bits are defined, so no need to waste space
          * with uint64_t at the moment.  We maintain the guests idea of the
          * value it wrote, and a value to install into hardware (extended to
-         * uint32_t to simplify the asm) which might be different.
+         * uint32_t to simplify the asm) which might be different.  HVM guests
+         * might be given direct access to the MSRs, at which point the
+         * 'guest' value becomes stale.
          */
         uint32_t host;
         uint8_t guest;
+        bool direct_access;
     } spec_ctrl;
 
     /* 0x00000140  MSR_INTEL_MISC_FEATURES_ENABLES */
