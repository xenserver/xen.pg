From d40029c844cf26802b50a41e02708eb33be54ff9 Mon Sep 17 00:00:00 2001
From: Paul Durrant <paul.durrant@citrix.com>
Date: Mon, 17 Dec 2018 09:22:57 +0000
Subject: [PATCH] iommu: rename wrapper functions

A subsequent patch will add semantically different versions of
iommu_map/unmap() so, in advance of that change, this patch renames the
existing functions to iommu_legacy_map/unmap() and modifies all call-sites.
It also adjusts a comment that refers to iommu_map_page(), which was re-
named by a previous patch.

This patch is purely cosmetic. No functional change.

Signed-off-by: Paul Durrant <paul.durrant@citrix.com>
Acked-by: Jan Beulich <jbeulich@suse.com>
Reviewed-by: Kevin Tian <kevin.tian@intel.com>
diff --git a/xen/arch/x86/mm.c b/xen/arch/x86/mm.c
index e0657e264c..1510ab3b57 100644
--- a/xen/arch/x86/mm.c
+++ b/xen/arch/x86/mm.c
@@ -2412,7 +2412,7 @@ static int cleanup_page_mappings(struct page_info *page)
 
         if ( d && is_pv_domain(d) && unlikely(need_iommu(d)) )
         {
-            int rc2 = iommu_unmap(d, mfn, PAGE_ORDER_4K);
+            int rc2 = iommu_legacy_unmap(d, mfn, PAGE_ORDER_4K);
 
             if ( !rc )
                 rc = rc2;
@@ -2891,12 +2891,14 @@ static int _get_page_type(struct page_info *page, unsigned long type,
             gfn_t gfn = _gfn(mfn_to_gmfn(d, mfn_x(page_to_mfn(page))));
 
             if ( (x & PGT_type_mask) == PGT_writable_page )
-                iommu_ret = iommu_unmap(d, gfn_x(gfn), PAGE_ORDER_4K);
+                iommu_ret = iommu_legacy_unmap(d, gfn_x(gfn),
+                                               PAGE_ORDER_4K);
             else if ( type == PGT_writable_page )
-                iommu_ret = iommu_map(d, gfn_x(gfn),
-                                      mfn_x(page_to_mfn(page)),
-                                      PAGE_ORDER_4K,
-                                      IOMMUF_readable | IOMMUF_writable);
+                iommu_ret = iommu_legacy_map(d, gfn_x(gfn),
+                                             mfn_x(page_to_mfn(page)),
+                                             PAGE_ORDER_4K,
+                                             IOMMUF_readable |
+                                             IOMMUF_writable);
 
             if ( unlikely(iommu_ret) )
             {
diff --git a/xen/arch/x86/mm/p2m-ept.c b/xen/arch/x86/mm/p2m-ept.c
index 49abda3999..80a742a4cd 100644
--- a/xen/arch/x86/mm/p2m-ept.c
+++ b/xen/arch/x86/mm/p2m-ept.c
@@ -885,8 +885,8 @@ out:
             rc = iommu_pte_flush(d, gfn, &ept_entry->epte, order, vtd_pte_present);
         else
             rc = iommu_flags ?
-                iommu_map(d, gfn, mfn_x(mfn), order, iommu_flags) :
-                iommu_unmap(d, gfn + i, order);
+                iommu_legacy_map(d, gfn, mfn_x(mfn), order, iommu_flags) :
+                iommu_legacy_unmap(d, gfn + i, order);
     }
 
     unmap_domain_page(table);
diff --git a/xen/arch/x86/mm/p2m-pt.c b/xen/arch/x86/mm/p2m-pt.c
index 08c044aa11..0b1c3f6122 100644
--- a/xen/arch/x86/mm/p2m-pt.c
+++ b/xen/arch/x86/mm/p2m-pt.c
@@ -698,9 +698,9 @@ p2m_pt_set_entry(struct p2m_domain *p2m, gfn_t gfn_, mfn_t mfn,
         }
         else
             rc = iommu_pte_flags ?
-                iommu_map(p2m->domain, gfn, mfn_x(mfn), page_order,
-                          iommu_pte_flags) :
-                iommu_unmap(p2m->domain, gfn, page_order);
+                iommu_legacy_map(p2m->domain, gfn, mfn_x(mfn), page_order,
+                                 iommu_pte_flags) :
+                iommu_legacy_unmap(p2m->domain, gfn, page_order);
     }
 
     /*
diff --git a/xen/arch/x86/mm/p2m.c b/xen/arch/x86/mm/p2m.c
index 3b8f8e262a..8f29d41c08 100644
--- a/xen/arch/x86/mm/p2m.c
+++ b/xen/arch/x86/mm/p2m.c
@@ -1316,8 +1316,8 @@ int set_identity_p2m_entry(struct domain *d, unsigned long gfn_l,
     {
         if ( !need_iommu(d) )
             return 0;
-        return iommu_map(d, gfn_l, gfn_l, PAGE_ORDER_4K,
-                         IOMMUF_readable | IOMMUF_writable);
+        return iommu_legacy_map(d, gfn_l, gfn_l, PAGE_ORDER_4K,
+                                IOMMUF_readable | IOMMUF_writable);
     }
 
     gfn_lock(p2m, gfn, 0);
@@ -1407,7 +1407,7 @@ int clear_identity_p2m_entry(struct domain *d, unsigned long gfn_l)
     {
         if ( !need_iommu(d) )
             return 0;
-        return iommu_unmap(d, gfn_l, PAGE_ORDER_4K);
+        return iommu_legacy_unmap(d, gfn_l, PAGE_ORDER_4K);
     }
 
     gfn_lock(p2m, gfn, 0);
diff --git a/xen/arch/x86/x86_64/mm.c b/xen/arch/x86/x86_64/mm.c
index 4c07fd12c1..eaea1d4b40 100644
--- a/xen/arch/x86/x86_64/mm.c
+++ b/xen/arch/x86/x86_64/mm.c
@@ -1429,14 +1429,14 @@ int memory_add(unsigned long spfn, unsigned long epfn, unsigned int pxm)
     if ( iommu_enabled && !iommu_passthrough && !need_iommu(hardware_domain) )
     {
         for ( i = spfn; i < epfn; i++ )
-            if ( iommu_map(hardware_domain, i, i, PAGE_ORDER_4K,
-                           IOMMUF_readable | IOMMUF_writable) )
+            if ( iommu_legacy_map(hardware_domain, i, i, PAGE_ORDER_4K,
+                                  IOMMUF_readable | IOMMUF_writable) )
                 break;
         if ( i != epfn )
         {
             while (i-- > old_max)
                 /* If statement to satisfy __must_check. */
-                if ( iommu_unmap(hardware_domain, i, PAGE_ORDER_4K) )
+                if ( iommu_legacy_unmap(hardware_domain, i, PAGE_ORDER_4K) )
                     continue;
 
             goto destroy_m2p;
diff --git a/xen/common/grant_table.c b/xen/common/grant_table.c
index 8d31a88210..cbc56dfb11 100644
--- a/xen/common/grant_table.c
+++ b/xen/common/grant_table.c
@@ -1148,14 +1148,14 @@ map_grant_ref(
              !(old_pin & (GNTPIN_hstw_mask|GNTPIN_devw_mask)) )
         {
             if ( !(kind & MAPKIND_WRITE) )
-                err = iommu_map(ld, mfn_x(frame), mfn_x(frame), 0,
-                                IOMMUF_readable | IOMMUF_writable);
+                err = iommu_legacy_map(ld, mfn_x(frame), mfn_x(frame), 0,
+                                       IOMMUF_readable | IOMMUF_writable);
         }
         else if ( act_pin && !old_pin )
         {
             if ( !kind )
-                err = iommu_map(ld, mfn_x(frame), mfn_x(frame), 0,
-                                IOMMUF_readable);
+                err = iommu_legacy_map(ld, mfn_x(frame), mfn_x(frame), 0,
+                                       IOMMUF_readable);
         }
         if ( err )
         {
@@ -1417,10 +1417,10 @@ unmap_common(
 
         kind = mapkind(lgt, rd, op->frame);
         if ( !kind )
-            err = iommu_unmap(ld, mfn_x(op->frame), 0);
+            err = iommu_legacy_unmap(ld, mfn_x(op->frame), 0);
         else if ( !(kind & MAPKIND_WRITE) )
-            err = iommu_map(ld, mfn_x(op->frame), mfn_x(op->frame), 0,
-                            IOMMUF_readable);
+            err = iommu_legacy_map(ld, mfn_x(op->frame), mfn_x(op->frame),
+                                   0, IOMMUF_readable);
 
         double_gt_unlock(lgt, rgt);
 
diff --git a/xen/drivers/passthrough/iommu.c b/xen/drivers/passthrough/iommu.c
index ba0a233bb1..5fda5e50a6 100644
--- a/xen/drivers/passthrough/iommu.c
+++ b/xen/drivers/passthrough/iommu.c
@@ -255,8 +255,8 @@ void iommu_domain_destroy(struct domain *d)
     arch_iommu_domain_destroy(d);
 }
 
-int iommu_map(struct domain *d, unsigned long gfn, unsigned long mfn,
-              unsigned int page_order, unsigned int flags)
+int iommu_legacy_map(struct domain *d, unsigned long gfn, unsigned long mfn,
+                     unsigned int page_order, unsigned int flags)
 {
     const struct domain_iommu *hd = dom_iommu(d);
     unsigned long i;
@@ -293,7 +293,8 @@ int iommu_map(struct domain *d, unsigned long gfn, unsigned long mfn,
     return rc;
 }
 
-int iommu_unmap(struct domain *d, unsigned long gfn, unsigned int page_order)
+int iommu_legacy_unmap(struct domain *d, unsigned long gfn,
+                       unsigned int page_order)
 {
     const struct domain_iommu *hd = dom_iommu(d);
     unsigned long i;
diff --git a/xen/drivers/passthrough/vtd/x86/vtd.c b/xen/drivers/passthrough/vtd/x86/vtd.c
index df117e6904..4d2d49ec2c 100644
--- a/xen/drivers/passthrough/vtd/x86/vtd.c
+++ b/xen/drivers/passthrough/vtd/x86/vtd.c
@@ -140,8 +140,8 @@ void __hwdom_init vtd_set_hwdom_mapping(struct domain *d)
         if ( xen_in_range(pfn) )
             continue;
 
-        rc = iommu_map(d, pfn, pfn, PAGE_SHIFT - PAGE_SHIFT_4K,
-                       IOMMUF_readable | IOMMUF_writable);
+        rc = iommu_legacy_map(d, pfn, pfn, PAGE_SHIFT - PAGE_SHIFT_4K,
+                              IOMMUF_readable | IOMMUF_writable);
         if ( rc )
            printk(XENLOG_WARNING VTDPREFIX " d%d: IOMMU mapping failed: %d\n",
                   d->domain_id, rc);
diff --git a/xen/include/xen/iommu.h b/xen/include/xen/iommu.h
index 5adbb4741b..7375256147 100644
--- a/xen/include/xen/iommu.h
+++ b/xen/include/xen/iommu.h
@@ -55,16 +55,16 @@ int iommu_construct(struct domain *d);
 /* Function used internally, use iommu_domain_destroy */
 void iommu_teardown(struct domain *d);
 
-/* iommu_map_page() takes flags to direct the mapping operation. */
 #define _IOMMUF_readable 0
 #define IOMMUF_readable  (1u<<_IOMMUF_readable)
 #define _IOMMUF_writable 1
 #define IOMMUF_writable  (1u<<_IOMMUF_writable)
-int __must_check iommu_map(struct domain *d, unsigned long gfn,
-                           unsigned long mfn, unsigned int page_order,
-                           unsigned int flags);
-int __must_check iommu_unmap(struct domain *d, unsigned long gfn,
-                             unsigned int page_order);
+int __must_check iommu_legacy_map(struct domain *d, unsigned long gfn,
+                                  unsigned long mfn,
+                                  unsigned int page_order,
+                                  unsigned int flags);
+int __must_check iommu_legacy_unmap(struct domain *d, unsigned long gfn,
+                                    unsigned int page_order);
 
 enum iommu_feature
 {
