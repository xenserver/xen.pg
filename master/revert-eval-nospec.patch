diff --git a/xen/arch/x86/hvm/hvm.c b/xen/arch/x86/hvm/hvm.c
index 977934a..5783626 100644
--- a/xen/arch/x86/hvm/hvm.c
+++ b/xen/arch/x86/hvm/hvm.c
@@ -4131,9 +4131,6 @@ static int hvmop_set_param(
     if ( a.index >= HVM_NR_PARAMS )
         return -EINVAL;
 
-    /* Make sure the above bound check is not bypassed during speculation. */
-    block_speculation();
-
     d = rcu_lock_domain_by_any_id(a.domid);
     if ( d == NULL )
         return -ESRCH;
@@ -4400,9 +4397,6 @@ static int hvmop_get_param(
     if ( a.index >= HVM_NR_PARAMS )
         return -EINVAL;
 
-    /* Make sure the above bound check is not bypassed during speculation. */
-    block_speculation();
-
     d = rcu_lock_domain_by_any_id(a.domid);
     if ( d == NULL )
         return -ESRCH;
diff --git a/xen/common/domain.c b/xen/common/domain.c
index 0733ee8..98ee4e3 100644
--- a/xen/common/domain.c
+++ b/xen/common/domain.c
@@ -1418,7 +1418,7 @@ long do_vcpu_op(int cmd, unsigned int vcpuid, XEN_GUEST_HANDLE_PARAM(void) arg)
     struct vcpu *v;
     long rc = 0;
 
-    if ( (v = domain_vcpu(d, vcpuid)) == NULL )
+    if ( vcpuid >= d->max_vcpus || (v = d->vcpu[vcpuid]) == NULL )
         return -ENOENT;
 
     switch ( cmd )
diff --git a/xen/common/grant_table.c b/xen/common/grant_table.c
index b34d520..1eabbf9 100644
--- a/xen/common/grant_table.c
+++ b/xen/common/grant_table.c
@@ -37,7 +37,6 @@
 #include <xen/paging.h>
 #include <xen/keyhandler.h>
 #include <xen/vmap.h>
-#include <xen/nospec.h>
 #include <xsm/xsm.h>
 #include <asm/flushtlb.h>
 #include <asm/guest_atomics.h>
@@ -205,9 +204,8 @@ static inline unsigned int nr_status_frames(const struct grant_table *gt)
 }
 
 #define MAPTRACK_PER_PAGE (PAGE_SIZE / sizeof(struct grant_mapping))
-#define maptrack_entry(t, e)                                                   \
-    ((t)->maptrack[array_index_nospec(e, (t)->maptrack_limit) /                \
-                                    MAPTRACK_PER_PAGE][(e) % MAPTRACK_PER_PAGE])
+#define maptrack_entry(t, e) \
+    ((t)->maptrack[(e)/MAPTRACK_PER_PAGE][(e)%MAPTRACK_PER_PAGE])
 
 static inline unsigned int
 nr_maptrack_frames(struct grant_table *t)
@@ -229,23 +227,10 @@ nr_maptrack_frames(struct grant_table *t)
 static grant_entry_header_t *
 shared_entry_header(struct grant_table *t, grant_ref_t ref)
 {
-    switch ( t->gt_version )
-    {
-    case 1:
-        /* Returned values should be independent of speculative execution */
-        block_speculation();
+    if ( t->gt_version == 1 )
         return (grant_entry_header_t*)&shared_entry_v1(t, ref);
-
-    case 2:
-        /* Returned values should be independent of speculative execution */
-        block_speculation();
+    else
         return &shared_entry_v2(t, ref).hdr;
-    }
-
-    ASSERT_UNREACHABLE();
-    block_speculation();
-
-    return NULL;
 }
 
 /* Active grant entry - used for shadowing GTF_permit_access grants. */
@@ -650,24 +635,14 @@ static unsigned int nr_grant_entries(struct grant_table *gt)
     case 1:
         BUILD_BUG_ON(f2e(INITIAL_NR_GRANT_FRAMES, 1) <
                      GNTTAB_NR_RESERVED_ENTRIES);
-
-        /* Make sure we return a value independently of speculative execution */
-        block_speculation();
         return f2e(nr_grant_frames(gt), 1);
-
     case 2:
         BUILD_BUG_ON(f2e(INITIAL_NR_GRANT_FRAMES, 2) <
                      GNTTAB_NR_RESERVED_ENTRIES);
-
-        /* Make sure we return a value independently of speculative execution */
-        block_speculation();
         return f2e(nr_grant_frames(gt), 2);
 #undef f2e
     }
 
-    ASSERT_UNREACHABLE();
-    block_speculation();
-
     return 0;
 }
 
@@ -827,7 +802,7 @@ static int _set_status(const grant_entry_header_t *shah,
                        domid_t ldomid)
 {
 
-    if ( evaluate_nospec(rgt_version == 1) )
+    if ( rgt_version == 1 )
         return _set_status_v1(shah, rd, act, readonly, mapflag, ldomid);
     else
         return _set_status_v2(shah, status, rd, act, readonly, mapflag, ldomid);
@@ -911,7 +886,6 @@ map_grant_ref(
 {
     struct domain *ld, *rd, *owner = NULL;
     struct grant_table *lgt, *rgt;
-    grant_ref_t ref;
     struct vcpu   *led;
     grant_handle_t handle;
     mfn_t mfn;
@@ -975,18 +949,13 @@ map_grant_ref(
     grant_read_lock(rgt);
 
     /* Bounds check on the grant ref */
-    ref = op->ref;
-    if ( unlikely(ref >= nr_grant_entries(rgt)))
+    if ( unlikely(op->ref >= nr_grant_entries(rgt)))
         PIN_FAIL(unlock_out, GNTST_bad_gntref, "Bad ref %#x for d%d\n",
-                 ref, rgt->domain->domain_id);
-
-    /* This call also ensures the above check cannot be passed speculatively */
-    shah = shared_entry_header(rgt, ref);
-    act = active_entry_acquire(rgt, ref);
+                 op->ref, rgt->domain->domain_id);
 
-    /* Make sure we do not access memory speculatively */
-    status = evaluate_nospec(rgt->gt_version == 1) ? &shah->flags
-                                                 : &status_entry(rgt, ref);
+    act = active_entry_acquire(rgt, op->ref);
+    shah = shared_entry_header(rgt, op->ref);
+    status = rgt->gt_version == 1 ? &shah->flags : &status_entry(rgt, op->ref);
 
     /* If already pinned, check the active domid and avoid refcnt overflow. */
     if ( act->pin &&
@@ -1008,9 +977,9 @@ map_grant_ref(
 
         if ( !act->pin )
         {
-            unsigned long gfn = evaluate_nospec(rgt->gt_version == 1) ?
-                                shared_entry_v1(rgt, ref).frame :
-                                shared_entry_v2(rgt, ref).full_page.frame;
+            unsigned long gfn = rgt->gt_version == 1 ?
+                                shared_entry_v1(rgt, op->ref).frame :
+                                shared_entry_v2(rgt, op->ref).full_page.frame;
 
             rc = get_paged_frame(gfn, &mfn, &pg,
                                  op->flags & GNTMAP_readonly, rd);
@@ -1023,7 +992,7 @@ map_grant_ref(
             act->length = PAGE_SIZE;
             act->is_sub_page = false;
             act->trans_domain = rd;
-            act->trans_gref = ref;
+            act->trans_gref = op->ref;
         }
     }
 
@@ -1274,7 +1243,6 @@ unmap_common(
     domid_t          dom;
     struct domain   *ld, *rd;
     struct grant_table *lgt, *rgt;
-    grant_ref_t ref;
     struct active_grant_entry *act;
     s16              rc = 0;
     struct grant_mapping *map;
@@ -1328,7 +1296,6 @@ unmap_common(
 
     op->rd = rd;
     op->ref = map->ref;
-    ref = map->ref;
 
     /*
      * We can't assume there was no racing unmap for this maptrack entry,
@@ -1338,7 +1305,7 @@ unmap_common(
      * invalid lock.
      */
     smp_rmb();
-    if ( unlikely(ref >= nr_grant_entries(rgt)) )
+    if ( unlikely(op->ref >= nr_grant_entries(rgt)) )
     {
         gdprintk(XENLOG_WARNING, "Unstable d%d handle %#x\n",
                  rgt->domain->domain_id, op->handle);
@@ -1347,10 +1314,7 @@ unmap_common(
         goto unlock_out;
     }
 
-    /* Make sure the above bound check cannot be bypassed speculatively */
-    block_speculation();
-
-    act = active_entry_acquire(rgt, ref);
+    act = active_entry_acquire(rgt, op->ref);
 
     /*
      * Note that we (ab)use the active entry lock here to protect against
@@ -1363,7 +1327,7 @@ unmap_common(
     flags = read_atomic(&map->flags);
     smp_rmb();
     if ( unlikely(!flags) || unlikely(map->domid != dom) ||
-         unlikely(map->ref != ref) )
+         unlikely(map->ref != op->ref) )
     {
         gdprintk(XENLOG_WARNING, "Unstable handle %#x\n", op->handle);
         rc = GNTST_bad_handle;
@@ -1448,7 +1412,7 @@ unmap_common_complete(struct gnttab_unmap_common *op)
     uint16_t *status;
     unsigned int clear_flags = 0;
 
-    if ( evaluate_nospec(!op->done) )
+    if ( !op->done )
     {
         /* unmap_common() didn't do anything - nothing to complete. */
         return;
@@ -1464,7 +1428,7 @@ unmap_common_complete(struct gnttab_unmap_common *op)
     act = active_entry_acquire(rgt, op->ref);
     sha = shared_entry_header(rgt, op->ref);
 
-    if ( evaluate_nospec(rgt->gt_version == 1) )
+    if ( rgt->gt_version == 1 )
         status = &sha->flags;
     else
         status = &status_entry(rgt, op->ref);
@@ -1660,10 +1624,6 @@ gnttab_populate_status_frames(struct domain *d, struct grant_table *gt,
     unsigned req_status_frames;
 
     req_status_frames = grant_to_status_frames(req_nr_frames);
-
-    /* Make sure, prior version checks are architectural visible */
-    block_speculation();
-
     for ( i = nr_status_frames(gt); i < req_status_frames; i++ )
     {
         if ( (gt->status[i] = alloc_xenheap_page()) == NULL )
@@ -1692,9 +1652,6 @@ gnttab_unpopulate_status_frames(struct domain *d, struct grant_table *gt)
 {
     unsigned int i;
 
-    /* Make sure, prior version checks are architectural visible */
-    block_speculation();
-
     for ( i = 0; i < nr_status_frames(gt); i++ )
     {
         struct page_info *pg = virt_to_page(gt->status[i]);
@@ -1805,7 +1762,7 @@ gnttab_grow_table(struct domain *d, unsigned int req_nr_frames)
     }
 
     /* Status pages - version 2 */
-    if ( evaluate_nospec(gt->gt_version > 1) )
+    if ( gt->gt_version > 1 )
     {
         if ( gnttab_populate_status_frames(d, gt, req_nr_frames) )
             goto shared_alloc_failed;
@@ -2065,7 +2022,6 @@ gnttab_prepare_for_transfer(
         goto fail;
     }
 
-    /* This call also ensures the above check cannot be passed speculatively */
     raw_shah = (uint32_t *)shared_entry_header(rgt, ref);
     scombo.raw = ACCESS_ONCE(*raw_shah);
 
@@ -2262,12 +2218,7 @@ gnttab_transfer(
         spin_unlock(&e->page_alloc_lock);
         okay = gnttab_prepare_for_transfer(e, d, gop.ref);
 
-        /*
-         * Make sure the reference bound check in gnttab_prepare_for_transfer
-         * is respected and speculative execution is blocked accordingly
-         */
-        if ( unlikely(!evaluate_nospec(okay)) ||
-            unlikely(assign_pages(e, page, 0, MEMF_no_refcount)) )
+        if ( unlikely(!okay || assign_pages(e, page, 0, MEMF_no_refcount)) )
         {
             bool drop_dom_ref;
 
@@ -2299,7 +2250,7 @@ gnttab_transfer(
         grant_read_lock(e->grant_table);
         act = active_entry_acquire(e->grant_table, gop.ref);
 
-        if ( evaluate_nospec(e->grant_table->gt_version == 1) )
+        if ( e->grant_table->gt_version == 1 )
         {
             grant_entry_v1_t *sha = &shared_entry_v1(e->grant_table, gop.ref);
 
@@ -2361,7 +2312,7 @@ release_grant_for_copy(
     sha = shared_entry_header(rgt, gref);
     mfn = act->mfn;
 
-    if ( evaluate_nospec(rgt->gt_version == 1) )
+    if ( rgt->gt_version == 1 )
     {
         status = &sha->flags;
         td = rd;
@@ -2465,11 +2416,9 @@ acquire_grant_for_copy(
         PIN_FAIL(gt_unlock_out, GNTST_bad_gntref,
                  "Bad grant reference %#x\n", gref);
 
-    /* This call also ensures the above check cannot be passed speculatively */
-    shah = shared_entry_header(rgt, gref);
     act = active_entry_acquire(rgt, gref);
-
-    if ( evaluate_nospec(rgt->gt_version == 1) )
+    shah = shared_entry_header(rgt, gref);
+    if ( rgt->gt_version == 1 )
     {
         sha2 = NULL;
         status = &shah->flags;
@@ -2887,9 +2836,6 @@ static int gnttab_copy_buf(const struct gnttab_copy *op,
                  op->dest.offset, dest->ptr.offset,
                  op->len, dest->len);
 
-    /* Make sure the above checks are not bypassed speculatively */
-    block_speculation();
-
     memcpy(dest->virt + op->dest.offset, src->virt + op->source.offset,
            op->len);
     gnttab_mark_dirty(dest->domain, dest->mfn);
@@ -3009,7 +2955,7 @@ gnttab_set_version(XEN_GUEST_HANDLE_PARAM(gnttab_set_version_t) uop)
     struct grant_table *gt = currd->grant_table;
     grant_entry_v1_t reserved_entries[GNTTAB_NR_RESERVED_ENTRIES];
     int res;
-    unsigned int i, nr_ents;
+    unsigned int i;
 
     if ( copy_from_guest(&op, uop, 1) )
         return -EFAULT;
@@ -3033,8 +2979,7 @@ gnttab_set_version(XEN_GUEST_HANDLE_PARAM(gnttab_set_version_t) uop)
      * are allowed to be in use (xenstore/xenconsole keeps them mapped).
      * (You need to change the version number for e.g. kexec.)
      */
-    nr_ents = nr_grant_entries(gt);
-    for ( i = GNTTAB_NR_RESERVED_ENTRIES; i < nr_ents; i++ )
+    for ( i = GNTTAB_NR_RESERVED_ENTRIES; i < nr_grant_entries(gt); i++ )
     {
         if ( read_atomic(&_active_entry(gt, i).pin) != 0 )
         {
@@ -3276,9 +3221,6 @@ swap_grant_ref(grant_ref_t ref_a, grant_ref_t ref_b)
     if ( unlikely(ref_b >= nr_grant_entries(d->grant_table)))
         PIN_FAIL(out, GNTST_bad_gntref, "Bad ref-b %#x\n", ref_b);
 
-    /* Make sure the above checks are not bypassed speculatively */
-    block_speculation();
-
     /* Swapping the same ref is a no-op. */
     if ( ref_a == ref_b )
         goto out;
@@ -3291,7 +3233,7 @@ swap_grant_ref(grant_ref_t ref_a, grant_ref_t ref_b)
     if ( act_b->pin )
         PIN_FAIL(out, GNTST_eagain, "ref b %#x busy\n", ref_b);
 
-    if ( evaluate_nospec(gt->gt_version == 1) )
+    if ( gt->gt_version == 1 )
     {
         grant_entry_v1_t shared;
 
@@ -3753,14 +3695,13 @@ void grant_table_warn_active_grants(struct domain *d)
     struct grant_table *gt = d->grant_table;
     struct active_grant_entry *act;
     grant_ref_t ref;
-    unsigned int nr_active = 0, nr_ents;
+    unsigned int nr_active = 0;
 
 #define WARN_GRANT_MAX 10
 
     grant_read_lock(gt);
 
-    nr_ents = nr_grant_entries(gt);
-    for ( ref = 0; ref != nr_ents; ref++ )
+    for ( ref = 0; ref != nr_grant_entries(gt); ref++ )
     {
         act = active_entry_acquire(gt, ref);
         if ( !act->pin )
@@ -3845,7 +3786,7 @@ int mem_sharing_gref_to_gfn(struct grant_table *gt, grant_ref_t ref,
         rc = -EINVAL;
     else if ( ref >= nr_grant_entries(gt) )
         rc = -ENOENT;
-    else if ( evaluate_nospec(gt->gt_version == 1) )
+    else if ( gt->gt_version == 1 )
     {
         const grant_entry_v1_t *sha1 = &shared_entry_v1(gt, ref);
 
@@ -3867,7 +3808,7 @@ int mem_sharing_gref_to_gfn(struct grant_table *gt, grant_ref_t ref,
         rc = -ENXIO;
     else if ( !rc && status )
     {
-        if ( evaluate_nospec(gt->gt_version == 1) )
+        if ( gt->gt_version == 1 )
             *status = flags;
         else
             *status = status_entry(gt, ref);
@@ -3887,9 +3828,6 @@ static int gnttab_get_status_frame_mfn(struct domain *d,
 
     ASSERT(gt->gt_version == 2);
 
-    /* Make sure we have version equal to 2 even under speculation */
-    block_speculation();
-
     if ( idx >= nr_status_frames(gt) )
     {
         unsigned long nr_status;
@@ -3913,9 +3851,7 @@ static int gnttab_get_status_frame_mfn(struct domain *d,
             return -EINVAL;
     }
 
-    /* Make sure idx is bounded wrt nr_status_frames */
-    *mfn = _mfn(virt_to_mfn(
-                gt->status[array_index_nospec(idx, nr_status_frames(gt))]));
+    *mfn = _mfn(virt_to_mfn(gt->status[idx]));
     return 0;
 }
 
@@ -3944,9 +3880,7 @@ static int gnttab_get_shared_frame_mfn(struct domain *d,
             return -EINVAL;
     }
 
-    /* Make sure idx is bounded wrt nr_status_frames */
-    *mfn = _mfn(virt_to_mfn(
-                gt->shared_raw[array_index_nospec(idx, nr_grant_frames(gt))]));
+    *mfn = _mfn(virt_to_mfn(gt->shared_raw[idx]));
     return 0;
 }
 
@@ -3958,7 +3892,7 @@ int gnttab_map_frame(struct domain *d, unsigned long idx, gfn_t gfn, mfn_t *mfn)
 
     grant_write_lock(gt);
 
-    if ( evaluate_nospec(gt->gt_version == 2) && (idx & XENMAPIDX_grant_table_status) )
+    if ( gt->gt_version == 2 && (idx & XENMAPIDX_grant_table_status) )
     {
         idx &= ~XENMAPIDX_grant_table_status;
         status = true;
@@ -4016,7 +3950,6 @@ static void gnttab_usage_print(struct domain *rd)
     int first = 1;
     grant_ref_t ref;
     struct grant_table *gt = rd->grant_table;
-    unsigned int nr_ents;
 
     printk("      -------- active --------       -------- shared --------\n");
     printk("[ref] localdom mfn      pin          localdom gmfn     flags\n");
@@ -4029,8 +3962,7 @@ static void gnttab_usage_print(struct domain *rd)
            nr_grant_frames(gt), gt->max_grant_frames,
            nr_maptrack_frames(gt), gt->max_maptrack_frames);
 
-    nr_ents = nr_grant_entries(gt);
-    for ( ref = 0; ref != nr_ents; ref++ )
+    for ( ref = 0; ref != nr_grant_entries(gt); ref++ )
     {
         struct active_grant_entry *act;
         struct grant_entry_header *sha;
diff --git a/xen/common/pdx.c b/xen/common/pdx.c
index c91875f..69ed853 100644
--- a/xen/common/pdx.c
+++ b/xen/common/pdx.c
@@ -18,7 +18,6 @@
 #include <xen/init.h>
 #include <xen/mm.h>
 #include <xen/bitops.h>
-#include <xen/nospec.h>
 
 /* Parameters for PFN/MADDR compression. */
 unsigned long __read_mostly max_pdx;
@@ -34,9 +33,8 @@ unsigned long __read_mostly pdx_group_valid[BITS_TO_LONGS(
 
 bool __mfn_valid(unsigned long mfn)
 {
-    if ( unlikely(evaluate_nospec(mfn >= max_page)) )
-        return false;
-    return likely(!(mfn & pfn_hole_mask)) &&
+    return likely(mfn < max_page) &&
+           likely(!(mfn & pfn_hole_mask)) &&
            likely(test_bit(pfn_to_pdx(mfn) / PDX_GROUP_COUNT,
                            pdx_group_valid));
 }
diff --git a/xen/include/asm-arm/nospec.h b/xen/include/asm-arm/nospec.h
deleted file mode 100644
index 51c7aea..0000000
--- a/xen/include/asm-arm/nospec.h
+++ /dev/null
@@ -1,25 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. */
-
-#ifndef _ASM_ARM_NOSPEC_H
-#define _ASM_ARM_NOSPEC_H
-
-static inline bool evaluate_nospec(bool condition)
-{
-    return condition;
-}
-
-static inline void block_speculation(void)
-{
-}
-
-#endif /* _ASM_ARM_NOSPEC_H */
-
-/*
- * Local variables:
- * mode: C
- * c-file-style: "BSD"
- * c-basic-offset: 4
- * indent-tabs-mode: nil
- * End:
- */
diff --git a/xen/include/asm-x86/nospec.h b/xen/include/asm-x86/nospec.h
deleted file mode 100644
index 2aa47b3..0000000
--- a/xen/include/asm-x86/nospec.h
+++ /dev/null
@@ -1,39 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. */
-
-#ifndef _ASM_X86_NOSPEC_H
-#define _ASM_X86_NOSPEC_H
-
-#include <asm/alternative.h>
-
-/* Allow to insert a read memory barrier into conditionals */
-static always_inline bool barrier_nospec_true(void)
-{
-#ifdef CONFIG_HVM
-    alternative("", "lfence", X86_FEATURE_SC_L1TF_VULN);
-#endif
-    return true;
-}
-
-/* Allow to protect evaluation of conditionasl with respect to speculation */
-static always_inline bool evaluate_nospec(bool condition)
-{
-    return condition ? barrier_nospec_true() : !barrier_nospec_true();
-}
-
-/* Allow to block speculative execution in generic code */
-static always_inline void block_speculation(void)
-{
-    barrier_nospec_true();
-}
-
-#endif /* _ASM_X86_NOSPEC_H */
-
-/*
- * Local variables:
- * mode: C
- * c-file-style: "BSD"
- * c-basic-offset: 4
- * indent-tabs-mode: nil
- * End:
- */
diff --git a/xen/include/xen/nospec.h b/xen/include/xen/nospec.h
index 2ac8fec..8acfa60 100644
--- a/xen/include/xen/nospec.h
+++ b/xen/include/xen/nospec.h
@@ -8,7 +8,6 @@
 #define XEN_NOSPEC_H
 
 #include <asm/system.h>
-#include <asm/nospec.h>
 
 /**
  * array_index_mask_nospec() - generate a ~0 mask when index < size, 0 otherwise
diff --git a/xen/include/xen/sched.h b/xen/include/xen/sched.h
index a689622..a0035a1 100644
--- a/xen/include/xen/sched.h
+++ b/xen/include/xen/sched.h
@@ -902,17 +902,16 @@ void watchdog_domain_destroy(struct domain *d);
  *    (that is, this would not be suitable for a driver domain)
  *  - There is never a reason to deny the hardware domain access to this
  */
-#define is_hardware_domain(_d) evaluate_nospec((_d) == hardware_domain)
+#define is_hardware_domain(_d) ((_d) == hardware_domain)
 
 /* This check is for functionality specific to a control domain */
-#define is_control_domain(_d) evaluate_nospec((_d)->is_privileged)
+#define is_control_domain(_d) ((_d)->is_privileged)
 
 #define VM_ASSIST(d, t) (test_bit(VMASST_TYPE_ ## t, &(d)->vm_assist))
 
 static inline bool is_pv_domain(const struct domain *d)
 {
-    return IS_ENABLED(CONFIG_PV) &&
-        evaluate_nospec(!(d->options & XEN_DOMCTL_CDF_hvm));
+    return IS_ENABLED(CONFIG_PV) && !(d->options & XEN_DOMCTL_CDF_hvm);
 }
 
 static inline bool is_pv_vcpu(const struct vcpu *v)
@@ -943,8 +942,7 @@ static inline bool is_pv_64bit_vcpu(const struct vcpu *v)
 #endif
 static inline bool is_hvm_domain(const struct domain *d)
 {
-    return IS_ENABLED(CONFIG_HVM) &&
-        evaluate_nospec(d->options & XEN_DOMCTL_CDF_hvm);
+    return IS_ENABLED(CONFIG_HVM) && (d->options & XEN_DOMCTL_CDF_hvm);
 }
 
 static inline bool is_hvm_vcpu(const struct vcpu *v)
@@ -956,7 +954,7 @@ static inline bool hap_enabled(const struct domain *d)
 {
     /* sanitise_domain_config() rejects HAP && !HVM */
     return IS_ENABLED(CONFIG_HVM) &&
-        evaluate_nospec(d->options & XEN_DOMCTL_CDF_hap);
+        (d->options & XEN_DOMCTL_CDF_hap);
 }
 
 static inline bool is_hwdom_pinned_vcpu(const struct vcpu *v)
@@ -977,7 +975,7 @@ static inline bool is_xenstore_domain(const struct domain *d)
 
 static inline bool is_iommu_enabled(const struct domain *d)
 {
-    return evaluate_nospec(d->options & XEN_DOMCTL_CDF_iommu);
+    return d->options & XEN_DOMCTL_CDF_iommu;
 }
 
 extern bool sched_smt_power_savings;
