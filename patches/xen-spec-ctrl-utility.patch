From 65b3f145b0383b55444dc3a95cd4d18ea5655fff Mon Sep 17 00:00:00 2001
From: Sergey Dyasli <sergey.dyasli@citrix.com>
Date: Tue, 26 Mar 2019 09:53:25 +0000
Subject: x86: add XEN_SYSCTL_spec_ctrl and xen-spec-ctrl utility

stop_machine infrastructure is copied from live ucode update.
CPUID level 0x00000007:0.edx is updated on each cpu.
CPUID policies are recalculated if there are any CPUID changes.

Signed-off-by: Sergey Dyasli <sergey.dyasli@citrix.com>

diff --git a/tools/misc/.gitignore b/tools/misc/.gitignore
index 73ce95e6d77e..7593e2e92425 100644
--- a/tools/misc/.gitignore
+++ b/tools/misc/.gitignore
@@ -1,5 +1,6 @@
 xen-access
 xen-mceinj
 xen-memshare
+xen-spec-ctrl
 xen-ucode
 xen-vmtrace
diff --git a/tools/misc/Makefile b/tools/misc/Makefile
index 1c6e1d6a0471..72deede11a3a 100644
--- a/tools/misc/Makefile
+++ b/tools/misc/Makefile
@@ -24,6 +24,7 @@ INSTALL_SBIN-$(CONFIG_X86)     += xen-lowmemd
 INSTALL_SBIN-$(CONFIG_X86)     += xen-mceinj
 INSTALL_SBIN-$(CONFIG_X86)     += xen-memshare
 INSTALL_SBIN-$(CONFIG_X86)     += xen-mfndump
+INSTALL_SBIN-$(CONFIG_X86)     += xen-spec-ctrl
 INSTALL_SBIN-$(CONFIG_X86)     += xen-ucode
 INSTALL_SBIN-$(CONFIG_X86)     += xen-vmtrace
 INSTALL_SBIN                   += xencov
@@ -138,4 +139,7 @@ xencov: xencov.o
 xen-ucode: xen-ucode.o
 	$(CC) $(LDFLAGS) -o $@ $< $(LDLIBS_libxenctrl) $(APPEND_LDFLAGS)
 
+xen-spec-ctrl: xen-spec-ctrl.o
+	$(CC) $(LDFLAGS) -o $@ $< $(LDLIBS_libxenctrl) $(APPEND_LDFLAGS)
+
 -include $(DEPS_INCLUDE)
diff --git a/tools/misc/xen-spec-ctrl.c b/tools/misc/xen-spec-ctrl.c
new file mode 100644
index 000000000000..d46778eca989
--- /dev/null
+++ b/tools/misc/xen-spec-ctrl.c
@@ -0,0 +1,60 @@
+#define _GNU_SOURCE
+
+#include <stdio.h>
+#include <err.h>
+#include <errno.h>
+#include <string.h>
+
+#include <xenctrl.h>
+
+void show_help(void)
+{
+    fprintf(stderr,
+            "xen-spec-ctrl: Xen speculation control tool\n"
+            "Usage: xen-spec-ctrl update\n");
+}
+
+int main(int argc, char *argv[])
+{
+    int ret;
+    struct xen_sysctl sysctl = {0};
+    xc_interface *xch;
+    char *str = "Mitigations have been updated! "
+                "Check xen-cpuid output for the details.";
+
+    if ( argc < 2 || strcmp(argv[1], "update") != 0 )
+    {
+        show_help();
+        return 1;
+    }
+
+    xch = xc_interface_open(NULL, NULL, 0);
+    if ( xch == NULL )
+        err(1, "xc_interface_open");
+
+    sysctl.interface_version = XEN_SYSCTL_INTERFACE_VERSION;
+    sysctl.cmd = XEN_SYSCTL_spec_ctrl;
+    sysctl.u.spec_ctrl.op = XENPF_spec_ctrl_update;
+
+    ret = xc_sysctl(xch, &sysctl);
+    if ( ret != 0 )
+    {
+        switch ( errno )
+        {
+        case ENOEXEC:
+            str = "No new H/W features have been found. "
+                  "Did you forget to update the microcode with xen-ucode?";
+            break;
+
+        default:
+            str = strerror(errno);
+            break;
+        }
+    }
+
+    fprintf(stderr, "Status: %s\n", str);
+
+    xc_interface_close(xch);
+
+    return 0;
+}
diff --git a/xen/arch/x86/cpu-policy.c b/xen/arch/x86/cpu-policy.c
index 2de625380836..bcb46d34cdf0 100644
--- a/xen/arch/x86/cpu-policy.c
+++ b/xen/arch/x86/cpu-policy.c
@@ -17,26 +17,26 @@
 #include <asm/xstate.h>
 
 struct cpu_policy __read_mostly       raw_cpu_policy;
-struct cpu_policy __ro_after_init    host_cpu_policy;
+struct cpu_policy __read_mostly      host_cpu_policy;
 #ifdef CONFIG_PV
-struct cpu_policy __ro_after_init  pv_max_cpu_policy;
-struct cpu_policy __ro_after_init  pv_def_cpu_policy;
+struct cpu_policy __read_mostly    pv_max_cpu_policy;
+struct cpu_policy __read_mostly    pv_def_cpu_policy;
 #endif
 #ifdef CONFIG_HVM
-struct cpu_policy __ro_after_init hvm_max_cpu_policy;
-struct cpu_policy __ro_after_init hvm_def_cpu_policy;
+struct cpu_policy __read_mostly   hvm_max_cpu_policy;
+struct cpu_policy __read_mostly   hvm_def_cpu_policy;
 #endif
 
 const uint32_t known_features[] = INIT_KNOWN_FEATURES;
 
-static const uint32_t __initconst pv_max_featuremask[] = INIT_PV_MAX_FEATURES;
+static const uint32_t pv_max_featuremask[] = INIT_PV_MAX_FEATURES;
 static const uint32_t hvm_shadow_max_featuremask[] = INIT_HVM_SHADOW_MAX_FEATURES;
-static const uint32_t __initconst hvm_hap_max_featuremask[] =
+static const uint32_t hvm_hap_max_featuremask[] =
     INIT_HVM_HAP_MAX_FEATURES;
-static const uint32_t __initconst pv_def_featuremask[] = INIT_PV_DEF_FEATURES;
-static const uint32_t __initconst hvm_shadow_def_featuremask[] =
+static const uint32_t pv_def_featuremask[] = INIT_PV_DEF_FEATURES;
+static const uint32_t hvm_shadow_def_featuremask[] =
     INIT_HVM_SHADOW_DEF_FEATURES;
-static const uint32_t __initconst hvm_hap_def_featuremask[] =
+static const uint32_t hvm_hap_def_featuremask[] =
     INIT_HVM_HAP_DEF_FEATURES;
 static const uint32_t deep_features[] = INIT_DEEP_FEATURES;
 
@@ -373,7 +373,7 @@ void calculate_raw_cpu_policy(void)
     /* Was already added by probe_cpuid_faulting() */
 }
 
-static void __init calculate_host_policy(void)
+static void calculate_host_policy(void)
 {
     struct cpu_policy *p = &host_cpu_policy;
     unsigned int max_extd_leaf;
@@ -425,7 +425,7 @@ static void __init calculate_host_policy(void)
     p->platform_info.cpuid_faulting = cpu_has_cpuid_faulting;
 }
 
-static void __init guest_common_max_feature_adjustments(uint32_t *fs)
+static void guest_common_max_feature_adjustments(uint32_t *fs)
 {
     if ( boot_cpu_data.x86_vendor == X86_VENDOR_INTEL )
     {
@@ -473,7 +473,7 @@ static void __init guest_common_max_feature_adjustments(uint32_t *fs)
      __set_bit(X86_FEATURE_CMP_LEGACY, fs);
 }
 
-static void __init guest_common_default_feature_adjustments(uint32_t *fs)
+static void guest_common_default_feature_adjustments(uint32_t *fs)
 {
     /* CMP_LEGACY is AMD/Hygon-only. Strip it from CPUs that don't have it */
     __clear_bit(X86_FEATURE_CMP_LEGACY, fs);
@@ -523,7 +523,7 @@ static void __init guest_common_default_feature_adjustments(uint32_t *fs)
         __clear_bit(X86_FEATURE_RTM, fs);
 }
 
-static void __init guest_common_feature_adjustments(uint32_t *fs)
+static void guest_common_feature_adjustments(uint32_t *fs)
 {
     /* Unconditionally claim to be able to set the hypervisor bit. */
     __set_bit(X86_FEATURE_HYPERVISOR, fs);
@@ -547,7 +547,7 @@ static void __init guest_common_feature_adjustments(uint32_t *fs)
         __set_bit(X86_FEATURE_IBPB, fs);
 }
 
-static void __init calculate_pv_max_policy(void)
+static void calculate_pv_max_policy(void)
 {
     struct cpu_policy *p = &pv_max_cpu_policy;
     uint32_t fs[FSCAPINTS];
@@ -614,7 +614,7 @@ static void __init calculate_pv_def_policy(void)
     recalculate_xstate(p);
 }
 
-static void __init calculate_hvm_max_policy(void)
+static void calculate_hvm_max_policy(void)
 {
     struct cpu_policy *p = &hvm_max_cpu_policy;
     uint32_t fs[FSCAPINTS];
@@ -755,7 +755,7 @@ static void __init calculate_hvm_def_policy(void)
     recalculate_xstate(p);
 }
 
-void __init init_guest_cpu_policies(void)
+void init_guest_cpu_policies(void)
 {
     calculate_raw_cpu_policy();
     calculate_host_policy();
diff --git a/xen/arch/x86/cpu/amd.c b/xen/arch/x86/cpu/amd.c
index 2838725bab98..1aaf1625a474 100644
--- a/xen/arch/x86/cpu/amd.c
+++ b/xen/arch/x86/cpu/amd.c
@@ -52,7 +52,7 @@ boolean_param("allow_unsafe", opt_allow_unsafe);
 /* Signal whether the ACPI C1E quirk is required. */
 bool __read_mostly amd_acpi_c1e_quirk;
 bool __ro_after_init amd_legacy_ssbd;
-bool __initdata amd_virt_spec_ctrl;
+bool __ro_after_init amd_virt_spec_ctrl;
 
 static bool __read_mostly fam17_c6_disabled;
 
diff --git a/xen/arch/x86/cpu/common.c b/xen/arch/x86/cpu/common.c
index ebe785525dd3..de2e85b1c9f8 100644
--- a/xen/arch/x86/cpu/common.c
+++ b/xen/arch/x86/cpu/common.c
@@ -625,6 +625,139 @@ void identify_cpu(struct cpuinfo_x86 *c)
 	setup_doitm();
 }
 
+static void fill_featureset(uint32_t fs[FSCAPINTS])
+{
+    unsigned int i, max_leaf, max_extd, tmp;
+
+    BUILD_BUG_ON(FSCAPINTS != 22);
+
+    max_leaf = cpuid_eax(0);
+    if ( max_leaf >= 1 )
+        cpuid(1, &tmp, &tmp, &fs[FEATURESET_1c],  &fs[FEATURESET_1d]);
+
+    if ( max_leaf >= 7 )
+    {
+        unsigned int max_feat;
+
+        cpuid_count(7, 0, &max_feat, &fs[FEATURESET_7b0],
+                    &fs[FEATURESET_7c0], &fs[FEATURESET_7d0]);
+        if ( max_feat >= 1 )
+            cpuid_count(7, 1, &fs[FEATURESET_7a1], &fs[FEATURESET_7b1],
+                        &fs[FEATURESET_7c1], &fs[FEATURESET_7d1]);
+        if ( max_feat >= 2 )
+            cpuid_count(7, 2, &tmp, &tmp, &tmp, &fs[FEATURESET_7d2]);
+    }
+
+    if ( max_leaf >= 0xd )
+        cpuid_count(0xd, 1, &fs[FEATURESET_Da1], &tmp, &tmp, &tmp);
+
+    max_extd = cpuid_eax(0x80000000);
+    if ( (max_extd >> 16) != 0x8000 )
+        max_extd = 0;
+
+    if ( max_extd >= 0x80000001 )
+        cpuid(0x80000001, &tmp, &tmp, &fs[FEATURESET_e1c], &fs[FEATURESET_e1d]);
+    if ( max_extd >= 0x80000007 )
+        cpuid(0x80000007, &tmp, &tmp, &tmp, &fs[FEATURESET_e7d]);
+    if ( max_extd >= 0x80000008 )
+        cpuid(0x80000008, &tmp, &fs[FEATURESET_e8b], &tmp, &tmp);
+    if ( max_extd >= 0x80000021 )
+        cpuid(0x80000021, &fs[FEATURESET_e21a], &tmp, &tmp, &tmp);
+
+    if ( test_bit(X86_FEATURE_ARCH_CAPS, fs) )
+        rdmsr(MSR_ARCH_CAPABILITIES, fs[FEATURESET_m10Al], fs[FEATURESET_m10Ah]);
+
+    for ( i = 0; i < FSCAPINTS; ++i )
+    {
+        fs[i] |= forced_caps[i];
+        fs[i] &= known_features[i] & ~cleared_caps[i];
+    }
+}
+
+static void cf_check update_cpuid(void *data)
+{
+    volatile uint32_t *new_fs = data;
+    uint32_t fs[FSCAPINTS] = {};
+    unsigned int i, cpu = smp_processor_id();
+
+    fill_featureset(fs);
+
+    for ( i = 0; i < ARRAY_SIZE(fs); ++i )
+        /*
+         * The common case is no difference from the initiating CPU.  Only
+         * issue the atomic operation if it looks like we have bits to clear.
+         */
+        if ( new_fs[i] & ~fs[i] )
+            asm volatile ( "lock and %[fs], %[new_fs]"
+                           : [new_fs] "+m" (new_fs[i])
+                           : [fs] "r" (fs[i]) );
+
+    /*
+     * Update cpu_data[], but skip CPU0 for now.  boot_cpu_data needs to wait
+     * until all CPUs have merged.
+     */
+    if ( cpu != 0 )
+        memcpy(cpu_data[cpu].x86_capability, fs, sizeof(fs));
+}
+
+int sysctl_update_spec_ctrl_cpuid(void)
+{
+    uint32_t i, new_fs[FSCAPINTS] = {};
+    bool lost = false, updated = false;
+
+    /* Scan for new features on the current CPU. */
+    fill_featureset(new_fs);
+    for ( i = 0; i < ARRAY_SIZE(new_fs); ++i )
+        if ( new_fs[i] & ~boot_cpu_data.x86_capability[i] )
+            break;
+
+    /* If nothing new, don't bother querying other CPUs. */
+    if ( i == ARRAY_SIZE(new_fs) )
+        return -ENOEXEC;
+
+    /* If new features have appeared, check all CPUs. */
+    smp_call_function(update_cpuid, new_fs, 1);
+
+    /* Merge is complete.  First check for lost features. */
+    for ( i = 0; i < ARRAY_SIZE(new_fs); ++i )
+        if ( ~new_fs[i] & boot_cpu_data.x86_capability[i] )
+        {
+            if ( !lost )
+                printk(XENLOG_ERR "CPUID features lost\n");
+
+            printk(XENLOG_ERR "  featureset word %u, lost %08x\n",
+                   i, ~new_fs[i] & boot_cpu_data.x86_capability[i]);
+            lost = true;
+        }
+
+    if ( lost )
+    {
+        printk(XENLOG_ERR "Skipping data update, but system may be unstable\n");
+        return -EXDEV;
+    }
+
+    /* Update boot_cpu_data, printing new features. */
+    for ( i = 0; i < ARRAY_SIZE(new_fs); ++i )
+        if ( new_fs[i] & ~boot_cpu_data.x86_capability[i] )
+        {
+            if ( !updated )
+                printk(XENLOG_INFO "New CPUID features detected\n");
+
+            printk(XENLOG_INFO "  featureset word %u, new %08x\n",
+                   i, new_fs[i] & ~boot_cpu_data.x86_capability[i]);
+
+            ACCESS_ONCE(boot_cpu_data.x86_capability[i]) = new_fs[i];
+            updated = true;
+        }
+
+    if ( !updated )
+        return -ENOEXEC;
+
+    init_guest_cpu_policies();
+
+    return 0;
+}
+
 /* leaf 0xb SMT level */
 #define SMT_LEVEL       0
 
diff --git a/xen/arch/x86/include/asm/processor.h b/xen/arch/x86/include/asm/processor.h
index 7925e6b911f2..952debf67949 100644
--- a/xen/arch/x86/include/asm/processor.h
+++ b/xen/arch/x86/include/asm/processor.h
@@ -593,6 +593,8 @@ void tsx_init(void);
 void update_mcu_opt_ctrl(void);
 void set_in_mcu_opt_ctrl(uint32_t mask, uint32_t val);
 
+int sysctl_update_spec_ctrl_cpuid(void);
+
 enum ap_boot_method {
     AP_BOOT_NORMAL,
     AP_BOOT_SKINIT,
diff --git a/xen/arch/x86/sysctl.c b/xen/arch/x86/sysctl.c
index 42dc360ad6e9..fd5a498d521b 100644
--- a/xen/arch/x86/sysctl.c
+++ b/xen/arch/x86/sysctl.c
@@ -424,6 +424,33 @@ long arch_do_sysctl(
         break;
     }
 
+    case XEN_SYSCTL_spec_ctrl:
+        if ( sysctl->u.spec_ctrl.op != XENPF_spec_ctrl_update )
+        {
+            ret = -EINVAL;
+            break;
+        }
+
+        /*
+         * We're (potentially) updating the default CPUID/MSR settings for all
+         * VM types, and need to not race with with other consumers of the
+         * system policies:
+         *   XEN_DOMCTL_createdomain
+         *   XEN_SYSCTL_get_cpu_featureset
+         *   XEN_SYSCTL_get_cpu_policy
+         *
+         * We already hold the sysctl lock.  Take the domctl lock too.
+         */
+        if ( !domctl_lock_acquire() )
+        {
+            ret = -ERESTART;
+            break;
+        }
+
+        ret = sysctl_update_spec_ctrl_cpuid();
+        domctl_lock_release();
+        break;
+
     default:
         ret = -ENOSYS;
         break;
diff --git a/xen/arch/x86/xstate.c b/xen/arch/x86/xstate.c
index cea3d0b81f0b..a995cf9b8576 100644
--- a/xen/arch/x86/xstate.c
+++ b/xen/arch/x86/xstate.c
@@ -663,6 +663,7 @@ void xstate_init(struct cpuinfo_x86 *c)
 
     if ( bsp )
     {
+        setup_force_cpu_cap(X86_FEATURE_OSXSAVE);
         xfeature_mask = feature_mask;
         /*
          * xsave_cntxt_size is the max size required by enabled features.
diff --git a/xen/include/public/sysctl.h b/xen/include/public/sysctl.h
index ef4f364a74ff..db3422198c30 100644
--- a/xen/include/public/sysctl.h
+++ b/xen/include/public/sysctl.h
@@ -1052,6 +1052,11 @@ typedef struct xen_sysctl_cpu_policy xen_sysctl_cpu_policy_t;
 DEFINE_XEN_GUEST_HANDLE(xen_sysctl_cpu_policy_t);
 #endif
 
+struct xen_sysctl_spec_ctrl {
+#define XENPF_spec_ctrl_update  0 /* Try to use new mitigations */
+    uint32_t op;      /* IN */
+};
+
 struct xen_sysctl {
     uint32_t cmd;
 #define XEN_SYSCTL_readconsole                    1
@@ -1082,6 +1087,7 @@ struct xen_sysctl {
 #define XEN_SYSCTL_livepatch_op                  27
 /* #define XEN_SYSCTL_set_parameter              28 */
 #define XEN_SYSCTL_get_cpu_policy                29
+#define XEN_SYSCTL_spec_ctrl                    188
     uint32_t interface_version; /* XEN_SYSCTL_INTERFACE_VERSION */
     union {
         struct xen_sysctl_readconsole       readconsole;
@@ -1112,6 +1118,7 @@ struct xen_sysctl {
 #if defined(__i386__) || defined(__x86_64__)
         struct xen_sysctl_cpu_policy        cpu_policy;
 #endif
+        struct xen_sysctl_spec_ctrl         spec_ctrl;
         uint8_t                             pad[128];
     } u;
 };
