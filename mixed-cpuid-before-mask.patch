Add a new hypercall and libxc wrapper to get the CPUID feature leaves
as they were before and after the FlexMigrate/Extended Migration masks.

This is not the ideal way to do it - in particular I think probably
platform_ops is the wrong hypercall, and it definitely needs to
allocate a better cmd number before going upstream.

diff -r f36a910d2ce8 tools/libxc/xc_misc.c
--- a/tools/libxc/xc_misc.c
+++ b/tools/libxc/xc_misc.c
@@ -410,6 +410,31 @@ int xc_getcpuinfo(xc_interface *xch, int
 }
 
 
+int xc_get_boot_cpufeatures(xc_interface *xch,
+                            uint32_t *base_ecx, uint32_t *base_edx,
+                            uint32_t *ext_ecx, uint32_t *ext_edx,
+                            uint32_t *masked_base_ecx,
+                            uint32_t *masked_base_edx,
+                            uint32_t *masked_ext_ecx,
+                            uint32_t *masked_ext_edx)
+{
+    xen_platform_op_t pm = {0};
+    int rc;
+
+    pm.cmd = XENPF_get_cpu_features;
+    rc = do_platform(xch, &pm);
+
+    *base_ecx = pm.u.cpu_features.base_ecx;
+    *base_edx = pm.u.cpu_features.base_edx;
+    *ext_ecx = pm.u.cpu_features.ext_ecx;
+    *ext_edx = pm.u.cpu_features.ext_edx;
+    *masked_base_ecx = pm.u.cpu_features.masked_base_ecx;
+    *masked_base_edx = pm.u.cpu_features.masked_base_edx;
+    *masked_ext_ecx = pm.u.cpu_features.masked_ext_ecx;
+    *masked_ext_edx = pm.u.cpu_features.masked_ext_edx;
+    return rc;
+}
+
 int xc_hvm_set_pci_intx_level(
     xc_interface *xch, domid_t dom,
     uint8_t domain, uint8_t bus, uint8_t device, uint8_t intx,
diff -r f36a910d2ce8 tools/libxc/xc_private.c
--- a/tools/libxc/xc_private.c
+++ b/tools/libxc/xc_private.c
@@ -508,6 +508,32 @@ int xc_flush_mmu_updates(xc_interface *x
     return flush_mmu_updates(xch, mmu);
 }
 
+int do_platform(xc_interface *xch, struct xen_platform_op *pm)
+{
+    int ret = -1;
+    DECLARE_HYPERCALL;
+    DECLARE_HYPERCALL_BOUNCE(pm, sizeof(*pm), XC_HYPERCALL_BUFFER_BOUNCE_BOTH);
+
+    pm->interface_version = XENPF_INTERFACE_VERSION;
+    if ( xc_hypercall_bounce_pre(xch, pm) )
+    {
+        PERROR("Could not bounce memory for platform op hypercall");
+        return -1;
+    }
+
+    hypercall.op     = __HYPERVISOR_platform_op;
+    hypercall.arg[0] = HYPERCALL_BUFFER_AS_ARG(pm);
+    if ( (ret = do_xen_hypercall(xch, &hypercall)) < 0 )
+    {
+        if ( errno == EACCES )
+            DPRINTF("platform operation failed -- need to"
+                    " rebuild the user-space tool set?\n");
+    }
+
+    xc_hypercall_bounce_post(xch, pm);
+    return ret;
+}
+
 int do_memory_op(xc_interface *xch, int cmd, void *arg, size_t len)
 {
     DECLARE_HYPERCALL;
diff -r f36a910d2ce8 tools/libxc/xc_private.h
--- a/tools/libxc/xc_private.h
+++ b/tools/libxc/xc_private.h
@@ -191,6 +191,7 @@ void xc__hypercall_buffer_cache_release(
  */
 
 int do_xen_hypercall(xc_interface *xch, privcmd_hypercall_t *hypercall);
+int do_platform(xc_interface *xch, struct xen_platform_op *pm);
 
 static inline int do_xen_version(xc_interface *xch, int cmd, xc_hypercall_buffer_t *dest)
 {
diff -r f36a910d2ce8 tools/libxc/xenctrl.h
--- a/tools/libxc/xenctrl.h
+++ b/tools/libxc/xenctrl.h
@@ -38,6 +38,7 @@
 #include <xen/domctl.h>
 #include <xen/physdev.h>
 #include <xen/sysctl.h>
+#include <xen/platform.h>
 #include <xen/version.h>
 #include <xen/event_channel.h>
 #include <xen/sched.h>
@@ -98,6 +99,10 @@
  * between, and be compatible with, both versions.
  */
 
+#define XENCTRL_HAS_GET_CPUFEATURES 1
+/* xc_get_boot_cpufeatures is not upstream, so we use this to allow
+ * the ocaml bindings to conditionally-compile.
+ */
 
 /*
  *  GENERAL
@@ -2489,4 +2494,15 @@ int xc_kexec_load(xc_interface *xch, uin
  */
 int xc_kexec_unload(xc_interface *xch, int type);
 
+
+/* Get the CPUID feature lists before and after any hardware masks
+ * were applied.  Returns the ANDed aggregate of all online CPUs. */
+int xc_get_boot_cpufeatures(xc_interface *xc_handle,
+                            uint32_t *base_ecx, uint32_t *base_edx,
+                            uint32_t *ext_ecx, uint32_t *ext_edx,
+                            uint32_t *masked_base_ecx,
+                            uint32_t *masked_base_edx,
+                            uint32_t *masked_ext_ecx,
+                            uint32_t *masked_ext_edx);
+
 #endif /* XENCTRL_H */
diff -r f36a910d2ce8 tools/ocaml/libs/xc/xenctrl.ml
--- a/tools/ocaml/libs/xc/xenctrl.ml
+++ b/tools/ocaml/libs/xc/xenctrl.ml
@@ -278,6 +278,9 @@ external version_capabilities: handle ->
 external watchdog : handle -> int -> int32 -> int
   = "stub_xc_watchdog"
 
+external get_boot_cpufeatures: handle ->
+        (int32 * int32 * int32 * int32 * int32 * int32 * int32 * int32) = "stub_xc_get_boot_cpufeatures"
+
 (* core dump structure *)
 type core_magic = Magic_hvm | Magic_pv
 
diff -r f36a910d2ce8 tools/ocaml/libs/xc/xenctrl.mli
--- a/tools/ocaml/libs/xc/xenctrl.mli
+++ b/tools/ocaml/libs/xc/xenctrl.mli
@@ -210,3 +210,5 @@ external domain_cpuid_apply_policy: hand
 external cpuid_check: handle -> (int64 * (int64 option)) -> string option array -> (bool * string option array)
        = "stub_xc_cpuid_check"
 
+external get_boot_cpufeatures: handle ->
+        (int32 * int32 * int32 * int32 * int32 * int32 * int32 * int32) = "stub_xc_get_boot_cpufeatures"
diff -r f36a910d2ce8 tools/ocaml/libs/xc/xenctrl_stubs.c
--- a/tools/ocaml/libs/xc/xenctrl_stubs.c
+++ b/tools/ocaml/libs/xc/xenctrl_stubs.c
@@ -1325,6 +1325,30 @@ CAMLprim value stub_xc_domain_trigger_sl
 	CAMLreturn(Val_unit);
 }
 
+CAMLprim value stub_xc_get_boot_cpufeatures(value xch)
+{
+	CAMLparam1(xch);
+	CAMLlocal1(v);
+	uint32_t a, b, c, d, e, f, g, h;
+	int ret;
+
+	ret = xc_get_boot_cpufeatures(_H(xch), &a, &b, &c, &d, &e, &f, &g, &h);
+	if (ret < 0)
+		failwith_xc(_H(xch));
+
+	v = caml_alloc_tuple(8);
+	Store_field(v, 0, caml_copy_int32(a));
+	Store_field(v, 1, caml_copy_int32(b));
+	Store_field(v, 2, caml_copy_int32(c));
+	Store_field(v, 3, caml_copy_int32(d));
+	Store_field(v, 4, caml_copy_int32(e));
+	Store_field(v, 5, caml_copy_int32(f));
+	Store_field(v, 6, caml_copy_int32(g));
+	Store_field(v, 7, caml_copy_int32(h));
+
+	CAMLreturn(v);
+}
+
 /*
  * Local variables:
  *  indent-tabs-mode: t
diff -r f36a910d2ce8 xen/arch/x86/cpu/amd.c
--- a/xen/arch/x86/cpu/amd.c
+++ b/xen/arch/x86/cpu/amd.c
@@ -145,7 +145,7 @@ static const struct cpuidmask *__init no
  *
  * The processor revision string parameter has precedene.
  */
-static void __devinit set_cpuidmask(const struct cpuinfo_x86 *c)
+static void __devinit set_cpuidmask(struct cpuinfo_x86 *c)
 {
 	static unsigned int feat_ecx, feat_edx;
 	static unsigned int extfeat_ecx, extfeat_edx;
@@ -156,8 +156,11 @@ static void __devinit set_cpuidmask(cons
 	static enum { not_parsed, no_mask, set_mask } status;
 	unsigned int eax, ebx, ecx, edx;
 
+	cpuid(0x1, &eax, &ebx, &c->boot_base_ecx, &c->boot_base_edx);
+	cpuid(0x80000001, &eax, &ebx, &c->boot_ext_ecx, &c->boot_ext_edx);
+
 	if (status == no_mask)
-		return;
+		goto nomask;
 
 	if (status == set_mask)
 		goto setmask;
@@ -167,7 +170,7 @@ static void __devinit set_cpuidmask(cons
 
 	/* Fam11 doesn't support masking at all. */
 	if (c->x86 == 0x11)
-		return;
+		goto nomask;
 
 	if (~(opt_cpuid_mask_ecx & opt_cpuid_mask_edx &
 	      opt_cpuid_mask_ext_ecx & opt_cpuid_mask_ext_edx &
@@ -181,14 +184,14 @@ static void __devinit set_cpuidmask(cons
 		l7s0_ebx = opt_cpuid_mask_l7s0_ebx;
 		thermal_ecx = opt_cpuid_mask_thermal_ecx;
 	} else if (*opt_famrev == '\0') {
-		return;
+		goto nomask;
 	} else {
 		const struct cpuidmask *m = get_cpuidmask(opt_famrev);
 
 		if (!m) {
 			printk("Invalid processor string: %s\n", opt_famrev);
 			printk("CPUID will not be masked\n");
-			return;
+			goto nomask;
 		}
 		feat_ecx = m->ecx;
 		feat_edx = m->edx;
@@ -258,6 +261,18 @@ static void __devinit set_cpuidmask(cons
 		skip_thermal_ecx = 1;
 		printk("Failed to set CPUID thermal/power feature mask\n");
 	}
+
+	c->masked_base_ecx = feat_ecx;
+	c->masked_base_edx = feat_edx;
+	c->masked_ext_ecx  = extfeat_ecx;
+	c->masked_ext_edx  = extfeat_edx;
+	return;
+
+ nomask:
+	c->masked_base_ecx = c->boot_base_ecx;
+	c->masked_base_edx = c->boot_base_edx;
+	c->masked_ext_ecx  = c->boot_ext_ecx;
+	c->masked_ext_edx  = c->boot_ext_edx;
 }
 
 /*
diff -r f36a910d2ce8 xen/arch/x86/cpu/intel.c
--- a/xen/arch/x86/cpu/intel.c
+++ b/xen/arch/x86/cpu/intel.c
@@ -61,14 +61,18 @@ void set_cpuid_faulting(bool_t enable)
  * edx = 0xBFEBFBFF when executing CPUID.EAX = 1 normally. If you want to
  * 'rev down' to E8400, you can set these values in these Xen boot parameters.
  */
-static void __devinit set_cpuidmask(const struct cpuinfo_x86 *c)
+static void __devinit set_cpuidmask(struct cpuinfo_x86 *c)
 {
+	u32 eax, ebx;
 	static unsigned int msr_basic, msr_ext, msr_xsave;
 	static enum { not_parsed, no_mask, set_mask } status;
 	u64 msr_val;
 
+	cpuid(0x1, &eax, &ebx, &c->boot_base_ecx, &c->boot_base_edx);
+	cpuid(0x80000001, &eax, &ebx, &c->boot_ext_ecx, &c->boot_ext_edx);
+
 	if (status == no_mask)
-		return;
+		goto nomask;
 
 	if (status == set_mask)
 		goto setmask;
@@ -79,12 +83,12 @@ static void __devinit set_cpuidmask(cons
 	if (!~(opt_cpuid_mask_ecx & opt_cpuid_mask_edx &
 	       opt_cpuid_mask_ext_ecx & opt_cpuid_mask_ext_edx &
 	       opt_cpuid_mask_xsave_eax))
-		return;
+		goto nomask;
 
 	/* Only family 6 supports this feature. */
 	if (c->x86 != 6) {
 		printk("No CPUID feature masking support available\n");
-		return;
+		goto nomask;
 	}
 
 	switch (c->x86_model) {
@@ -166,6 +170,16 @@ static void __devinit set_cpuidmask(cons
 		msr_xsave = 0;
 		printk("Failed to set CPUID xsave feature mask\n");
 	}
+
+	cpuid(0x1, &eax, &ebx, &c->masked_base_ecx, &c->masked_base_edx);
+	cpuid(0x80000001, &eax, &ebx, &c->masked_ext_ecx, &c->masked_ext_edx);
+	return;
+
+ nomask:
+	c->masked_base_ecx = c->boot_base_ecx;
+	c->masked_base_edx = c->boot_base_edx;
+	c->masked_ext_ecx  = c->boot_ext_ecx;
+	c->masked_ext_edx  = c->boot_ext_edx;
 }
 
 void __devinit early_intel_workaround(struct cpuinfo_x86 *c)
diff -r f36a910d2ce8 xen/arch/x86/platform_hypercall.c
--- a/xen/arch/x86/platform_hypercall.c
+++ b/xen/arch/x86/platform_hypercall.c
@@ -601,6 +601,34 @@ ret_t do_platform_op(XEN_GUEST_HANDLE_PA
     }
     break;
 
+    case XENPF_get_cpu_features:
+    {
+        uint32_t cpu;
+
+        op->u.cpu_features.base_ecx = 0xffffffff;
+        op->u.cpu_features.base_edx = 0xffffffff;
+        op->u.cpu_features.ext_ecx = 0xffffffff;
+        op->u.cpu_features.ext_edx = 0xffffffff;
+        op->u.cpu_features.masked_base_ecx = 0xffffffff;
+        op->u.cpu_features.masked_base_edx = 0xffffffff;
+        op->u.cpu_features.masked_ext_ecx = 0xffffffff;
+        op->u.cpu_features.masked_ext_edx = 0xffffffff;
+        for_each_online_cpu( cpu )
+        {
+            op->u.cpu_features.base_ecx &= cpu_data[cpu].boot_base_ecx;
+            op->u.cpu_features.base_edx &= cpu_data[cpu].boot_base_edx;
+            op->u.cpu_features.ext_ecx  &= cpu_data[cpu].boot_ext_ecx;
+            op->u.cpu_features.ext_edx  &= cpu_data[cpu].boot_ext_edx;
+            op->u.cpu_features.masked_base_ecx &= cpu_data[cpu].masked_base_ecx;
+            op->u.cpu_features.masked_base_edx &= cpu_data[cpu].masked_base_edx;
+            op->u.cpu_features.masked_ext_ecx  &= cpu_data[cpu].masked_ext_ecx;
+            op->u.cpu_features.masked_ext_edx  &= cpu_data[cpu].masked_ext_edx;
+        }
+
+        ret = copy_to_guest(u_xenpf_op, op, 1) ? -EFAULT : 0;
+    }
+    break;
+
     default:
         ret = -ENOSYS;
         break;
diff -r f36a910d2ce8 xen/include/public/platform.h
--- a/xen/include/public/platform.h
+++ b/xen/include/public/platform.h
@@ -527,6 +527,22 @@ struct xenpf_core_parking {
 typedef struct xenpf_core_parking xenpf_core_parking_t;
 DEFINE_XEN_GUEST_HANDLE(xenpf_core_parking_t);
 
+/* Get the CPUID feature lists before and after any hardware masks
+ * were applied.   Returns the ANDed aggregate of all online CPUs. */
+#define XENPF_get_cpu_features  511
+struct xenpf_cpu_features {
+    uint32_t base_ecx;          /* CPUID leaf 0x00000001:ECX */
+    uint32_t base_edx;          /* CPUID leaf 0x00000001:EDX */
+    uint32_t ext_ecx;           /* CPUID leaf 0x80000001:ECX */
+    uint32_t ext_edx;           /* CPUID leaf 0x80000001:EDX */
+    uint32_t masked_base_ecx;   /* CPUID leaf 0x00000001:ECX */
+    uint32_t masked_base_edx;   /* CPUID leaf 0x00000001:EDX */
+    uint32_t masked_ext_ecx;    /* CPUID leaf 0x80000001:ECX */
+    uint32_t masked_ext_edx;    /* CPUID leaf 0x80000001:EDX */
+};
+typedef struct xenpf_cpu_features xenpf_cpu_features_t;
+DEFINE_XEN_GUEST_HANDLE(xenpf_cpu_features_t);
+
 /*
  * ` enum neg_errnoval
  * ` HYPERVISOR_platform_op(const struct xen_platform_op*);
@@ -553,6 +569,7 @@ struct xen_platform_op {
         struct xenpf_cpu_hotadd        cpu_add;
         struct xenpf_mem_hotadd        mem_add;
         struct xenpf_core_parking      core_parking;
+        struct xenpf_cpu_features      cpu_features;
         uint8_t                        pad[128];
     } u;
 };
